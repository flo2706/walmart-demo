# ğŸ›’ PrÃ©diction des ventes Walmart â€” Rapport de synthÃ¨se

## ğŸ“‡ Contexte
**Walmart Inc.** est un distributeur amÃ©ricain fondÃ© par **Sam Walton** (1962), basÃ© Ã  Bentonville (Arkansas).  
**Objectif mÃ©tier :** construire un **modÃ¨le ML** pour estimer les **ventes hebdomadaires** par magasin, mieux comprendre lâ€™influence des indicateurs Ã©conomiques et **anticiper** les campagnes marketing.

---

## ğŸ¯ Objectifs du projet
1. **EDA + PrÃ©traitement** des donnÃ©es  
2. **ModÃ¨le baseline** : rÃ©gression linÃ©aire  
3. **RÃ©duction du surapprentissage** : rÃ©gressions **Ridge** et **Lasso** (tuning dâ€™Î±)

---

## ğŸ–¼ï¸ DonnÃ©es & Cible
- Dataset (version **JULIE**, inspirÃ©e de Kaggle) : ventes hebdomadaires par magasin + indicateurs (`Fuel_Price`, `CPI`, `Unemployment`, `Holiday_Flag`, etc.).
- **Cible** : `Weekly_Sales`.
- **Variables explicatives** (exemples) : `Store`, `Holiday_Flag`, `Temperature`, `Fuel_Price`, `CPI`, `Unemployment`, `month`, `day_of_month` (dÃ©rivÃ©es de `Date`).

---

## ğŸ§° MÃ©thodologie

### PrÃ©traitement (pipeline scikit-learn, sans fuite)
- **NumÃ©riques** : `SimpleImputer(strategy="median")` â†’ `StandardScaler`.  
- **CatÃ©gorielles** : `SimpleImputer(strategy="most_frequent")` â†’ `OneHotEncoder(drop="first", handle_unknown="ignore")`.  
- **Nettoyage** : suppression des lignes avec cible manquante ; traitement des valeurs extrÃªmes (rÃ¨gle **Â±3Ïƒ** lorsque pertinent).  
- **Features calendrier** : `month`, `day_of_month` (autres disponibles si besoin).

### Ã‰valuation
- **Hold-out** : `train/test = 80/20`.  
- **Validation croisÃ©e** : **KFold (10 folds)** intÃ©grÃ©e aux GridSearch / LassoCV.  
- **MÃ©triques** : **RÂ²**, **MAE**, **RMSE**.  
- **Analyses** : rÃ©sidus (centrage, dispersion), rÃ©els vs. prÃ©dits, coefficients.

---

## ğŸ“ˆ RÃ©sultats (jeu de test)

| ModÃ¨le | Î±* | CV RÂ² | Train RÂ² | **Test RÂ²** | **Test MAE** | **Test RMSE** | # features |
|---|---:|---:|---:|---:|---:|---:|---:|
| RÃ©gression linÃ©aire (baseline) | â€” | â€” | 0.997 | **0.954** | 119 722 | 145 447 | â€” |
| Ridge | 0.01 | 0.918 | 0.996 | **0.954** | 119 284 | 145 348 | â€” |
| Lasso | 450 | 0.941 | 0.994 | **0.950** | 119 094 | 150 965 | â€” |
| **Lasso (sÃ©lection) + Lasso (final)** | **â‰ˆ 100** | â€” | 0.982 | **0.956** | **112 010** | **142 942** | **17** |

**Lecture rapide**
- Tous les modÃ¨les expliquent ~**95 %** de la variance en test.  
- **Meilleur compromis prÃ©cision / parcimonie** : **Lasso (sÃ©lection) + Lasso (final)**  
  â†’ **Test RÂ² = 0.956**, **MAE/RMSE** les plus bas, **17 variables** seulement.  
- **Ridge** â‰ˆ baseline en performance mais sans parcimonie.  
- **Lasso** simple : RÂ² test un peu infÃ©rieur et RMSE plus Ã©levÃ©.

---

## ğŸ” InterprÃ©tation des coefficients (synthÃ¨se)
- Signal **robuste** et cohÃ©rent entre modÃ¨les : les **effets `Store_*`** dominent, complÃ©tÃ©s par quelques **effets calendrier** (ex. `month_12` positif, certains `day_of_month` nÃ©gatifs).  
- **Ridge** lisse les amplitudes (rÃ©duit la variance) mais ne met pas de coefficients Ã  0.  
- **Lasso** annule de nombreux petits effets â†’ **sÃ©lection de variables**.  
- Le pipeline **Lasso sÃ©lection + Lasso final** retient ~**17** variables (magasins majeurs + calendrier) â†’ **interprÃ©table** et **performant**.

---

## ğŸ§ª Analyse des rÃ©sidus (rÃ©sumÃ©)
- RÃ©sidus **centrÃ©s** autour de 0 (pas de biais systÃ©matique).  
- **Dispersion** accrue pour les ventes extrÃªmes (lÃ©gÃ¨re hÃ©tÃ©roscÃ©dasticitÃ©) â†’ cohÃ©rent avec **RMSE > MAE**.  
- Nuage **rÃ©els vs. prÃ©dits** proche de la diagonale â†’ **bonne gÃ©nÃ©ralisation**.

---

## âœ… Conclusion & Recommandation
- **ModÃ¨le retenu** : **Pipeline _Lasso (sÃ©lection) + Lasso (final, Î± â‰ˆ 100)_**.  
  - **PrÃ©cision supÃ©rieure** (RÂ² test **0.956**, MAE/RMSE au plus bas)  
  - **Parcimonie** (17 features) â†’ **interprÃ©table** et **robuste**  
  - Gestion des catÃ©gories inÃ©dites par `OneHotEncoder(handle_unknown="ignore")` (encodÃ©es Ã  0 par dÃ©faut)

**Usages mÃ©tiers** : meilleure **prÃ©vision hebdomadaire**, **pilotage des stocks** et **planification marketing** ; comprÃ©hension des magasins/effets calendrier les plus structurants.

---

## ğŸ”­ Pistes dâ€™amÃ©lioration
- Ajouter des **features structurelles** (surface, trafic, mix produit) et des **interactions** (ex. `Holiday_Flag Ã— month`).  
- Regrouper les magasins (clustering) pour mieux gÃ©nÃ©raliser sur **petits volumes**.  
- Tester une cible transformÃ©e (**log(Weekly_Sales)**) pour attÃ©nuer lâ€™hÃ©tÃ©roscÃ©dasticitÃ©.

---

## ğŸ› ï¸ Stack technique
**Python**, **pandas**, **numpy**, **matplotlib**, **seaborn**, **scikit-learn**  
(Pipelines/ColumnTransformer, `LinearRegression`, `Ridge`, `Lasso`, **`LassoCV`**, `GridSearchCV`, `KFold`).
